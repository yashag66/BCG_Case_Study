{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc, count, col, dense_rank\n",
    "from pyspark.sql.window import Window\n",
    "import filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating spark session(spark entry point)\n",
    "spark = SparkSession.builder.appName('CaseStudySession').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to read CSV data in spark dataframe\n",
    "def read_csv_df(path='', header=True, inferSchema=True):\n",
    "    \"\"\"Method to read CSV file and return as a spark dataframe\n",
    "       This function will go through the input once to determine the input schema if\n",
    "       'inferSchema' is enabled. To avoid going through the entire data once, disable\n",
    "       \n",
    "    Parameters:\n",
    "        path: string for input path.\n",
    "        inferSchema: bool, optional\n",
    "            infers the input schema automatically from data. It requires one extra\n",
    "            pass over the data. It uses the default value, 'True'.\n",
    "        header: bool, optional\n",
    "            uses the first line as names of columns. It uses the default value, 'True'.\n",
    "    \"\"\"\n",
    "    if path:\n",
    "        return spark.read.csv(path, header=header, inferSchema=inferSchema).dropDuplicates()\n",
    "    raise Exception('Please provide file path')\n",
    "\n",
    "# Method to write CSV data from spark dataframe\n",
    "def write_csv_df(df=None, path='', header=True):\n",
    "    \"\"\"Method to write spark dataframe as CSV file\n",
    "    \n",
    "    Parameters:\n",
    "        df: spark dataframe which needs to written as file.\n",
    "        path: string for output path.\n",
    "        header: bool, optional\n",
    "            writes first line as names of columns. It uses the default value, 'True'.\n",
    "    \"\"\"\n",
    "\n",
    "    if path and df:\n",
    "        df.write.csv(path, header=header)\n",
    "        return\n",
    "    raise Exception('Please check file path and dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Primary Person Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRASH_ID: integer (nullable = true)\n",
      " |-- UNIT_NBR: integer (nullable = true)\n",
      " |-- PRSN_NBR: integer (nullable = true)\n",
      " |-- PRSN_TYPE_ID: string (nullable = true)\n",
      " |-- PRSN_OCCPNT_POS_ID: string (nullable = true)\n",
      " |-- PRSN_INJRY_SEV_ID: string (nullable = true)\n",
      " |-- PRSN_AGE: string (nullable = true)\n",
      " |-- PRSN_ETHNICITY_ID: string (nullable = true)\n",
      " |-- PRSN_GNDR_ID: string (nullable = true)\n",
      " |-- PRSN_EJCT_ID: string (nullable = true)\n",
      " |-- PRSN_REST_ID: string (nullable = true)\n",
      " |-- PRSN_AIRBAG_ID: string (nullable = true)\n",
      " |-- PRSN_HELMET_ID: string (nullable = true)\n",
      " |-- PRSN_SOL_FL: string (nullable = true)\n",
      " |-- PRSN_ALC_SPEC_TYPE_ID: string (nullable = true)\n",
      " |-- PRSN_ALC_RSLT_ID: string (nullable = true)\n",
      " |-- PRSN_BAC_TEST_RSLT: string (nullable = true)\n",
      " |-- PRSN_DRG_SPEC_TYPE_ID: string (nullable = true)\n",
      " |-- PRSN_DRG_RSLT_ID: string (nullable = true)\n",
      " |-- DRVR_DRG_CAT_1_ID: string (nullable = true)\n",
      " |-- PRSN_DEATH_TIME: string (nullable = true)\n",
      " |-- INCAP_INJRY_CNT: integer (nullable = true)\n",
      " |-- NONINCAP_INJRY_CNT: integer (nullable = true)\n",
      " |-- POSS_INJRY_CNT: integer (nullable = true)\n",
      " |-- NON_INJRY_CNT: integer (nullable = true)\n",
      " |-- UNKN_INJRY_CNT: integer (nullable = true)\n",
      " |-- TOT_INJRY_CNT: integer (nullable = true)\n",
      " |-- DEATH_CNT: integer (nullable = true)\n",
      " |-- DRVR_LIC_TYPE_ID: string (nullable = true)\n",
      " |-- DRVR_LIC_STATE_ID: string (nullable = true)\n",
      " |-- DRVR_LIC_CLS_ID: string (nullable = true)\n",
      " |-- DRVR_ZIP: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading Primary Person CSV Data in a spark dataframe\n",
    "primary_person_df = read_csv_df(filepaths.PRIMARY_PERSON_DATA_PATH, header=True, inferSchema=True)\n",
    "\n",
    "# Inferred Schema of primary person dataframe\n",
    "primary_person_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Units Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRASH_ID: integer (nullable = true)\n",
      " |-- UNIT_NBR: integer (nullable = true)\n",
      " |-- UNIT_DESC_ID: string (nullable = true)\n",
      " |-- VEH_PARKED_FL: string (nullable = true)\n",
      " |-- VEH_HNR_FL: string (nullable = true)\n",
      " |-- VEH_LIC_STATE_ID: string (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- VEH_MOD_YEAR: string (nullable = true)\n",
      " |-- VEH_COLOR_ID: string (nullable = true)\n",
      " |-- VEH_MAKE_ID: string (nullable = true)\n",
      " |-- VEH_MOD_ID: string (nullable = true)\n",
      " |-- VEH_BODY_STYL_ID: string (nullable = true)\n",
      " |-- EMER_RESPNDR_FL: string (nullable = true)\n",
      " |-- OWNR_ZIP: string (nullable = true)\n",
      " |-- FIN_RESP_PROOF_ID: string (nullable = true)\n",
      " |-- FIN_RESP_TYPE_ID: string (nullable = true)\n",
      " |-- VEH_DMAG_AREA_1_ID: string (nullable = true)\n",
      " |-- VEH_DMAG_SCL_1_ID: string (nullable = true)\n",
      " |-- FORCE_DIR_1_ID: string (nullable = true)\n",
      " |-- VEH_DMAG_AREA_2_ID: string (nullable = true)\n",
      " |-- VEH_DMAG_SCL_2_ID: string (nullable = true)\n",
      " |-- FORCE_DIR_2_ID: string (nullable = true)\n",
      " |-- VEH_INVENTORIED_FL: string (nullable = true)\n",
      " |-- VEH_TRANSP_NAME: string (nullable = true)\n",
      " |-- VEH_TRANSP_DEST: string (nullable = true)\n",
      " |-- CONTRIB_FACTR_1_ID: string (nullable = true)\n",
      " |-- CONTRIB_FACTR_2_ID: string (nullable = true)\n",
      " |-- CONTRIB_FACTR_P1_ID: string (nullable = true)\n",
      " |-- VEH_TRVL_DIR_ID: string (nullable = true)\n",
      " |-- FIRST_HARM_EVT_INV_ID: string (nullable = true)\n",
      " |-- INCAP_INJRY_CNT: integer (nullable = true)\n",
      " |-- NONINCAP_INJRY_CNT: integer (nullable = true)\n",
      " |-- POSS_INJRY_CNT: integer (nullable = true)\n",
      " |-- NON_INJRY_CNT: integer (nullable = true)\n",
      " |-- UNKN_INJRY_CNT: integer (nullable = true)\n",
      " |-- TOT_INJRY_CNT: integer (nullable = true)\n",
      " |-- DEATH_CNT: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading Primary Person CSV Data in a spark dataframe\n",
    "units_df = read_csv_df(filepaths.UNITS_DATA_PATH, header=True, inferSchema=True)\n",
    "\n",
    "# Inferred Schema of primary person dataframe\n",
    "units_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Charges Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRASH_ID: integer (nullable = true)\n",
      " |-- UNIT_NBR: integer (nullable = true)\n",
      " |-- PRSN_NBR: integer (nullable = true)\n",
      " |-- CHARGE: string (nullable = true)\n",
      " |-- CITATION_NBR: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading Primary Person CSV Data in a spark dataframe\n",
    "charges_df = read_csv_df(filepaths.CHARGES_DATA_PATH, header=True, inferSchema=True)\n",
    "\n",
    "# Inferred Schema of primary person dataframe\n",
    "charges_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Damages Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRASH_ID: integer (nullable = true)\n",
      " |-- DAMAGED_PROPERTY: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "damages_csv_path = './Data/Damages_use.csv'\n",
    "\n",
    "# Reading Primary Person CSV Data in a spark dataframe\n",
    "damages_df = read_csv_df(filepaths.DAMAGES_DATA_PATH, header=True, inferSchema=True)\n",
    "\n",
    "# Inferred Schema of primary person dataframe\n",
    "damages_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 1: Find the number of crashes (accidents) in which number of persons killed are male?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of crashes(accidents) in which number of persons killed are male: 180\n"
     ]
    }
   ],
   "source": [
    "# Filter accidents in which persons were killed should have PRSN_INJRY_SEV_ID set to 'KILLED'.\n",
    "# Filter accidents involving male should have PRSN_GNDR_ID set to 'MALE'.\n",
    "# After applying above two filters, get unique number of crashes/accidents using CRASH_ID.\n",
    "\n",
    "# primary_person_df.select('PRSN_GNDR_ID').distinct().collect()\n",
    "# primary_person_df.select('PRSN_INJRY_SEV_ID').distinct().collect()\n",
    "\n",
    "num_crashes_male = primary_person_df.filter('PRSN_INJRY_SEV_ID=\"KILLED\" AND PRSN_GNDR_ID=\"MALE\"') \\\n",
    "                   .select('CRASH_ID').distinct().count()\n",
    "\n",
    "print('Number of crashes(accidents) in which number of persons killed are male:', num_crashes_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 2: How many two wheelers are booked for crashes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of two wheelers which are booked for crashes: 766\n"
     ]
    }
   ],
   "source": [
    "# Filtering Units data for two wheelers i.e. 'POLICE MOTORCYCLE' OR 'MOTORCYCLE'\n",
    "# Getting unique Vehicle body styles => units_df.select('VEH_BODY_STYL_ID').distinct().collect()\n",
    "# Getting unique VIN(vehicle identification number) after applying the above filter.\n",
    "\n",
    "two_wheeler_vehicle_body = ['POLICE MOTORCYCLE', 'MOTORCYCLE']\n",
    "\n",
    "two_wheelers_crashes_df = units_df.filter(col('VEH_BODY_STYL_ID').isin(two_wheeler_vehicle_body)) \\\n",
    "                            .select('VIN').filter(col('VIN').isNotNull())\n",
    "\n",
    "print('Number of two wheelers which are booked for crashes:', two_wheelers_crashes_df.distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 3: Which state has highest number of accidents in which females are involved? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of crashes(accidents) in which number of persons are female: Texas\n"
     ]
    }
   ],
   "source": [
    "# Filter accidents involving FEMALE should have PRSN_GNDR_ID set to 'FEMALE'\n",
    "# Getting unique vehicle types => primary_person_df.select('PRSN_GNDR_ID').distinct().collect()\n",
    "# Assuming the state of accident same as driver licence state\n",
    "\n",
    "accident_female_df = primary_person_df.filter('PRSN_GNDR_ID=\"FEMALE\"')\n",
    "print('Number of crashes(accidents) in which number of persons are female:', \\\n",
    "          accident_female_df.select(['DRVR_LIC_STATE_ID', 'CRASH_ID']).distinct() \\\n",
    "          .groupby('DRVR_LIC_STATE_ID').count().orderBy(desc('count')).first()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 4: Which are the Top 5th to 15th VEH_MAKE_IDs that contribute to a largest number of injuries including death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|VEH_MAKE_ID|\n",
      "+-----------+\n",
      "|NISSAN     |\n",
      "|HONDA      |\n",
      "|GMC        |\n",
      "|HYUNDAI    |\n",
      "|KIA        |\n",
      "|JEEP       |\n",
      "|CHRYSLER   |\n",
      "|MAZDA      |\n",
      "|PONTIAC    |\n",
      "|VOLKSWAGEN |\n",
      "|LEXUS      |\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of values pertaining to injury including death\n",
    "# [row.PRSN_INJRY_SEV_ID for row in primary_person_df.select('PRSN_INJRY_SEV_ID').distinct().collect()]\n",
    "injury_flag_list = ['KILLED', 'NON-INCAPACITATING INJURY', 'POSSIBLE INJURY', 'INCAPACITATING INJURY']\n",
    "\n",
    "# Joining Units dataset with rimary person dataset to filter only the cashes involving injuries \n",
    "person_units_inner_join_df = primary_person_df.filter(col('PRSN_INJRY_SEV_ID').isin(injury_flag_list)) \\\n",
    "                            .select('CRASH_ID', 'UNIT_NBR') \\\n",
    "                            .join(units_df.select(['CRASH_ID', 'UNIT_NBR', 'VEH_MAKE_ID']), ['CRASH_ID', 'UNIT_NBR'], 'inner')\n",
    "\n",
    "# Counting unique crashes fo each VEH_MAKE_ID(Eliminating cases where VEH_MAKE_ID is NA)\n",
    "person_veh_make_df = person_units_inner_join_df.select('CRASH_ID', 'VEH_MAKE_ID').filter('VEH_MAKE_ID!=\"NA\"') \\\n",
    "                    .distinct().groupby('VEH_MAKE_ID').count().orderBy(desc('count'))\n",
    "\n",
    "# Assiging rank based on the crashes/count of each vehicle make\n",
    "windowSpec = Window.orderBy(desc('count'))\n",
    "person_veh_make_df = person_veh_make_df.withColumn('dense_rank', dense_rank().over(windowSpec))\n",
    "\n",
    "# Filtering top 5th to 15th VEH_MKE_IDs\n",
    "person_veh_make_df.filter('dense_rank>=5 AND dense_rank<=15').select(['VEH_MAKE_ID']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 5: For all the body styles involved in crashes, mention the top ethnic user group of each unique body style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----------------+\n",
      "|VEH_BODY_STYL_ID                 |PRSN_ETHNICITY_ID|\n",
      "+---------------------------------+-----------------+\n",
      "|AMBULANCE                        |WHITE            |\n",
      "|BUS                              |BLACK            |\n",
      "|FARM EQUIPMENT                   |WHITE            |\n",
      "|FIRE TRUCK                       |WHITE            |\n",
      "|MOTORCYCLE                       |WHITE            |\n",
      "|NEV-NEIGHBORHOOD ELECTRIC VEHICLE|WHITE            |\n",
      "|NOT REPORTED                     |WHITE            |\n",
      "|OTHER  (EXPLAIN IN NARRATIVE)    |WHITE            |\n",
      "|PASSENGER CAR, 2-DOOR            |WHITE            |\n",
      "|PASSENGER CAR, 4-DOOR            |WHITE            |\n",
      "|PICKUP                           |WHITE            |\n",
      "|POLICE CAR/TRUCK                 |WHITE            |\n",
      "|POLICE MOTORCYCLE                |WHITE            |\n",
      "|SPORT UTILITY VEHICLE            |WHITE            |\n",
      "|TRUCK                            |WHITE            |\n",
      "|TRUCK TRACTOR                    |WHITE            |\n",
      "|VAN                              |WHITE            |\n",
      "|YELLOW SCHOOL BUS                |BLACK            |\n",
      "+---------------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add logic to only use required columns not all whle joining two big datasets\n",
    "person_units_join_df = primary_person_df.join(units_df, ['CRASH_ID', 'UNIT_NBR'], 'outer')\n",
    "# person_units_join_df = primary_person_df.join(units_df, ['CRASH_ID', 'UNIT_NBR'], 'inner')\n",
    "\n",
    "# person_units_join_df.select(['PRSN_ETHNICITY_ID', 'VEH_BODY_STYL_ID', 'CRASH_ID', 'UNIT_NBR']).coalesce(1).write.csv('./Hello.csv', header=True)\n",
    "body_ethnic_df = person_units_join_df.select(['PRSN_ETHNICITY_ID', 'VEH_BODY_STYL_ID', 'CRASH_ID']) \\\n",
    "                .filter('VEH_BODY_STYL_ID!=\"NA\" AND VEH_BODY_STYL_ID!=\"UNKNOWN\"').distinct() \\\n",
    "                .groupby(['VEH_BODY_STYL_ID','PRSN_ETHNICITY_ID']) \\\n",
    "                .agg(count('CRASH_ID').alias('crash_count'))\n",
    "\n",
    "# Using dense rank to find the top ethnicity for each vehicle body styles\n",
    "windowSpec = Window.partitionBy('VEH_BODY_STYL_ID').orderBy(desc('crash_count'))\n",
    "body_ethnic_df = body_ethnic_df.withColumn('dense_rank', dense_rank().over(windowSpec))\n",
    "\n",
    "body_ethnic_df.filter('dense_rank=1').select(['VEH_BODY_STYL_ID','PRSN_ETHNICITY_ID']) \\\n",
    "                .orderBy('VEH_BODY_STYL_ID','PRSN_ETHNICITY_ID').show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 6: Among the crashed cars, what are the Top 5 Zip Codes with highest number crashes with alcohols as the contributing factor to a crash (Use Driver Zip Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|DRVR_ZIP|crash_count|\n",
      "+--------+-----------+\n",
      "|   78521|         45|\n",
      "|   79936|         35|\n",
      "|   76010|         35|\n",
      "|   79938|         31|\n",
      "|   78741|         27|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming the below vehichle body styles depict cars\n",
    "car_types = ['PASSENGER CAR, 2-DOOR', 'PASSENGER CAR, 4-DOOR', 'POLICE CAR/TRUCK', 'SPORT UTILITY VEHICLE', \n",
    "             'NEV-NEIGHBORHOOD ELECTRIC VEHICLE', 'VAN']\n",
    "\n",
    "# Filtering for persons with positive alcohol result\n",
    "# Filtering for vehicles being car\n",
    "# Ignoring records with driver zip not being null\n",
    "crashed_car_alcohol_zip_df = person_units_join_df.filter((col('PRSN_ALC_RSLT_ID')=='Positive') \\\n",
    "                            & (col('DRVR_ZIP').isNotNull()) & (col('VEH_BODY_STYL_ID').isin(car_types))) \\\n",
    "                            .select(['CRASH_ID', 'DRVR_ZIP', 'VEH_BODY_STYL_ID']).distinct()\n",
    "\n",
    "crashed_car_alcohol_zip_df.select(['CRASH_ID', 'DRVR_ZIP']).distinct().groupby('DRVR_ZIP') \\\n",
    "    .agg(count('CRASH_ID').alias('crash_count')).orderBy(desc('crash_count')).limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 7: Count of Distinct Crash IDs where No Damaged Property was observed and Damage Level (VEH_DMAG_SCL~) is above 4 and car avails Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Damage flag which depict damage level above 4\n",
    "damage_flag = ['DAMAGED 5', 'DAMAGED 6', 'DAMAGED 7 HIGHEST']\n",
    "\n",
    "# Adding Damages data to Units Data having damage level above 4(Join)\n",
    "damages_units_join_df = units_df.filter((col('VEH_DMAG_SCL_1_ID').isin(damage_flag)) | (col('VEH_DMAG_SCL_2_ID').isin(damage_flag))) \\\n",
    "                        .join(damages_df, ['CRASH_ID'], 'inner')\n",
    "\n",
    "# No Damages Flags\n",
    "no_damage_property_flag = [row.DAMAGED_PROPERTY \\\n",
    "                           for row in list(damages_units_join_df.select('DAMAGED_PROPERTY').distinct().collect()) \\\n",
    "                           if 'NO DAMAGE' in str(row.DAMAGED_PROPERTY).upper()]\n",
    "\n",
    "# List of unique Financial Responsibility Type\n",
    "# distinct_fin_res_id = [row.FIN_RESP_TYPE_ID for row in list(units_df.select('FIN_RESP_TYPE_ID').distinct().collect())]\n",
    "# List of Responsibility type pertaining to insurance and it's type\n",
    "# insurance_flag = ['INSURANCE BINDER', 'LIABILITY INSURANCE POLICY', 'CERTIFICATE OF SELF-INSURANCE',\n",
    "#                   'CERTIFICATE OF DEPOSIT WITH COUNTY JUDGE', 'CERTIFICATE OF DEPOSIT WITH COMPTROLLER',\n",
    "#                   'SURETY BOND', 'PROOF OF LIABILITY INSURANCE']\n",
    "\n",
    "non_insurance_flag = ['NA']\n",
    "\n",
    "# Filtering for vehicles which have insurance and the vehicles are of car type\n",
    "# Filtering for vehicles which didnt damage property\n",
    "damages_units_join_df.filter((~col('FIN_RESP_TYPE_ID').isin(non_insurance_flag)) \\\n",
    "                & (person_units_join_df.VEH_BODY_STYL_ID.isin(car_types)) \\\n",
    "                & (col('DAMAGED_PROPERTY').isin(no_damage_property_flag)) \\\n",
    "               ).select('CRASH_ID').distinct().count()                                                                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 8: Determine the Top 5 Vehicle Makes where drivers are charged with speeding related offences, has licensed Drivers, uses top 10 used vehicle colours and has car licensed with the Top 25 states with highest number of offences (to be deduced from the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|VEH_MAKE_ID|\n",
      "+-----------+\n",
      "|       FORD|\n",
      "|  CHEVROLET|\n",
      "|     TOYOTA|\n",
      "|      DODGE|\n",
      "|      HONDA|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Speeding related offences flags\n",
    "speeding_flag = [row.CHARGE for row in list(charges_df.select('CHARGE').distinct().collect()) if 'SPEED' in str(row.CHARGE).upper()]\n",
    "\n",
    "# offense_flag = [row.CHARGE for row in list(charges_df.select('CHARGE').distinct().collect()) if 'OFFENSE' in str(row.CHARGE).upper()]\n",
    "\n",
    "# Filtering for car crashes\n",
    "car_types = ['PASSENGER CAR, 2-DOOR', 'PASSENGER CAR, 4-DOOR', 'POLICE CAR/TRUCK', 'SPORT UTILITY VEHICLE', \n",
    "             'NEV-NEIGHBORHOOD ELECTRIC VEHICLE', 'VAN']\n",
    "\n",
    "# DRIVER LICENSE TYPE\n",
    "license_type_id = ['COMMERCIAL DRIVER LIC.', 'OCCUPATIONAL', 'DRIVER LICENSE'] \n",
    "\n",
    "# List of 25 states with highest car crashes(Assuming crash can be cosidered as an offense)\n",
    "states_highest_car_crash = [row.VEH_LIC_STATE_ID for row in list(units_df.filter(person_units_join_df.VEH_BODY_STYL_ID.isin(car_types)).select(['CRASH_ID', 'VEH_LIC_STATE_ID']).distinct().groupby('VEH_LIC_STATE_ID').count().orderBy(desc('count')).limit(25).collect())]\n",
    "\n",
    "# Top 10 used vehicle colours\n",
    "top_vehicle_colors = [row.VEH_COLOR_ID for row in \\\n",
    "                      list(units_df.select('CRASH_ID', 'VEH_COLOR_ID').filter('VEH_COLOR_ID!=\"NA\"') \\\n",
    "                           .groupby('VEH_COLOR_ID').count().orderBy(desc('count')).select('VEH_COLOR_ID') \\\n",
    "                           .limit(10).collect())]\n",
    "\n",
    "person_units_join_df.filter((col('VEH_COLOR_ID').isin(top_vehicle_colors)) \\\n",
    "    & (col('VEH_LIC_STATE_ID').isin(states_highest_car_crash)) \\\n",
    "    & (col('DRVR_LIC_TYPE_ID').isin(license_type_id))) \\\n",
    "    .join(charges_df.filter(col('CHARGE').isin(speeding_flag)), ['CRASH_ID', 'UNIT_NBR'], 'inner') \\\n",
    "    .select(['VEH_MAKE_ID', 'CRASH_ID', 'UNIT_NBR']).distinct() \\\n",
    "    .groupby('VEH_MAKE_ID').count().orderBy(desc('count')).select('VEH_MAKE_ID').limit(5).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
